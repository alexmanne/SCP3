{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Interface\n",
    "\n",
    "This Jupyter notebook is intended to assist in the post processing analysis of Single Cell Proteomic data.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "The following cell contains all of the necessary import for this notebook to run. Please make sure this is run every time you wish to work with the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import read_files as rf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Files\n",
    "\n",
    "Read in the protein/peptide files as well as the settings file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell calls one function that accepts one variable called filelist. It is a list of dictionaries and allows you to analyze multiple protein/peptide file  duos at the same time.   \n",
    "\n",
    "**Syntax** \n",
    "\n",
    "The general syntax should look like square brackets \"[]\" around a list of curly brackets \"{}\" that are separated by commas.     \n",
    "\n",
    "The curly brackets \"{}\" denote a dictionary which is another list of items separated by commas. This time however, each item in the list contains a key:value pair. The key is the type of file (\"protein_file\") and the value is the name of the actual file \"input/report.pg_matrix.tsv\".     \n",
    "\n",
    "Example of a dictionary:     \n",
    "{\"protein_file\": \"input/report.pg_matrix.tsv\",    \n",
    " \"peptide_file\": \"input/report.pr_matrix.tsv\",\n",
    " \"processing app\": \"diann\"}\n",
    "\n",
    "Example of a list: \n",
    "[        \n",
    "{dictionary from above},   \n",
    "     \n",
    "{second dictionary}     \n",
    "]\n",
    "\n",
    "\n",
    "**Notes**\n",
    "\n",
    "_Note 1_: Place the file_name in quotes. If the file is in a sub folder, write the name of the subfolder, followed by a \"/\", then the name of the file.\n",
    "\n",
    "_Note 2_: The following columns are required in the tsv files for the program to run\n",
    "- Protein.Names\n",
    "- Protein.Group (just in protein)\n",
    "- Precursor.Id (just in peptide)\n",
    "- File names (with / in the name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Sequence', 'Organism'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 18\u001b[0m\n\u001b[1;32m      1\u001b[0m filelist \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprotein_file\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput/report.pg_matrix.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      3\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpeptide_file\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput/report.pr_matrix.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m      }\n\u001b[1;32m     16\u001b[0m ]\n\u001b[0;32m---> 18\u001b[0m data_obj \u001b[38;5;241m=\u001b[39m \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilelist\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/KellyLab/SCP3/read_files.py:295\u001b[0m, in \u001b[0;36mread_files\u001b[0;34m(filelist)\u001b[0m\n\u001b[1;32m    292\u001b[0m use_maxlfq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Read the file and append it to data_objects\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m data_obj \u001b[38;5;241m=\u001b[39m \u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotein_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprotein_file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpeptide_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpeptide_file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mfile_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mprocessing_app\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfile_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprocessing_app\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmin_unique_peptides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_unique_peptides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m                     \u001b[49m\u001b[43muse_maxlfq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_maxlfq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m data_objects\u001b[38;5;241m.\u001b[39mappend(data_obj)\n\u001b[1;32m    303\u001b[0m i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Documents/KellyLab/SCP3/read_files.py:225\u001b[0m, in \u001b[0;36mread_file\u001b[0;34m(protein_file, peptide_file, file_id, processing_app, min_unique_peptides, use_maxlfq)\u001b[0m\n\u001b[1;32m    219\u001b[0m     prot_abundance, pep_abundance \u001b[38;5;241m=\u001b[39m fragpipe_22_tables(protein_file, peptide_file,\n\u001b[1;32m    220\u001b[0m                                                        min_unique_peptides, use_maxlfq)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m## Rename the DataFrames with run_IDs ##\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;66;03m# Create a list of the run_IDs\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m run_names \u001b[38;5;241m=\u001b[39m \u001b[43mpep_abundance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSequence\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOrganism\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[1;32m    226\u001b[0m num_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(run_names)\n\u001b[1;32m    227\u001b[0m ID_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mstr\u001b[39m(file_id) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(x)\n",
      "File \u001b[0;32m~/Documents/KellyLab/.venvchem/lib/python3.11/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Sequence', 'Organism'] not found in axis\""
     ]
    }
   ],
   "source": [
    "filelist = [\n",
    "    {\"protein_file\": \"input/report.pg_matrix.tsv\", \n",
    "     \"peptide_file\": \"input/report.pr_matrix.tsv\",\n",
    "     \"processing_app\": \"diann\"\n",
    "     },\n",
    "     \n",
    "    {\"protein_file\": \"input/HYE_prot_matrix.tsv\", \n",
    "     \"peptide_file\": \"input/HYE_pep_matrix.tsv\",\n",
    "     \"processing_app\": \"diann\"\n",
    "     },\n",
    "\n",
    "    {\"protein_file\": \"input/fragpipe_combined_protein.tsv\", \n",
    "     \"peptide_file\": \"input/fragpipe_combined_peptide.tsv\",\n",
    "     \"processing_app\": \"fragpipe\"\n",
    "     }\n",
    "]\n",
    "\n",
    "data_obj = rf.read_files(filelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Settings File can be used to tell the program how to filter, group, and name the data.\n",
    "\n",
    "The program expects the settings file to be tab-delimited. This means there is a grid like structure to the file with tabs separating the columns. To create or edit a settings file, open it in excel, make the edits, then save the file as a Tab delimited Text (.txt) file. This should be an option in the \"Save as\" on Excel.\n",
    "\n",
    "The settings file has 4 required columns: \"Conditions\", \"filter_in\", \"filter_out\", and \"Organism\"\n",
    "\n",
    "- Conditions:\n",
    "  - This is the name of the differing groups in the data. This creates a group that lines up with the row.\n",
    "  - Ex: \"human a\" or \"bacteria b\"\n",
    "\n",
    "- filter_in:\n",
    "  - This is a part of the file name (column) that you wish to include in the group. If you wish to add multiple snippets, separate them by commas.\n",
    "  - Ex: \"Hela_1cpw\" or \"HYEA_250pg\"\n",
    "\n",
    "- filter_out:\n",
    "  - This is a part of the file name (column) that you wish to specifically exclude from the group. If you wish to add multiple snippets, separate them by commas.\n",
    "  - Ex: \"Hela_1cpw\" or \"HYEA_250pg\"\n",
    "\n",
    "- Organism:\n",
    "  - This is organism you wish to include in this group (needs to be ALL CAPS like it is in the Protein.Names column)\n",
    "  - Ex: \"HUMAN\" or \"ECOLI\"\n",
    "\n",
    "After these columns, you may add other columns to further group the data together. For example, if you wished to group all yeast and human data, you can add a fifth column called \"Combined\", with the name \"Yeast_Human\" on each row of yeast and each row of human, then \"Other\" in every other row."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvchem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
